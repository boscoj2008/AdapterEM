2022-09-02 16:42:03 INFO     ====PromptEM Args====
2022-09-02 16:42:03 INFO     seed: 2022
2022-09-02 16:42:03 INFO     device: cuda
2022-09-02 16:42:03 INFO     model_name_or_path: roberta-base
2022-09-02 16:42:03 INFO     model_type: roberta
2022-09-02 16:42:03 INFO     batch_size: 16
2022-09-02 16:42:03 INFO     text_summarize: True
2022-09-02 16:42:03 INFO     learning_rate: 0.0001
2022-09-02 16:42:03 INFO     max_length: 512
2022-09-02 16:42:03 INFO     add_token: True
2022-09-02 16:42:03 INFO     data_name: semi-text-w
2022-09-02 16:42:03 INFO     template_no: 0
2022-09-02 16:42:03 INFO     self_training: False
2022-09-02 16:42:03 INFO     dynamic_dataset: -1
2022-09-02 16:42:03 INFO     k: 0.1
2022-09-02 16:42:03 INFO     num_iter: 1
2022-09-02 16:42:03 INFO     pseudo_label_method: uncertainty
2022-09-02 16:42:03 INFO     confidence_ratio: 0.1
2022-09-02 16:42:03 INFO     mc_dropout_pass: 10
2022-09-02 16:42:03 INFO     uncertainty_ratio: 0.05
2022-09-02 16:42:03 INFO     el2n_ratio: 0.05
2022-09-02 16:42:03 INFO     save_model: False
2022-09-02 16:42:03 INFO     only_plm: True
2022-09-02 16:42:03 INFO     teacher_epochs: 1000
2022-09-02 16:42:03 INFO     student_epochs: 30
2022-09-02 16:42:03 INFO     test_pseudo_label: 
2022-09-02 16:42:03 INFO     one_word: False
2022-09-02 16:42:26 INFO     num_sample_pos: 64
2022-09-02 16:42:26 INFO     num_sample_neg: 490
2022-09-02 16:42:26 INFO     left size: 9234, right size: 9234
2022-09-02 16:42:26 INFO     labeled train size: 554
2022-09-02 16:42:26 INFO     unlabeled train size: 4986
2022-09-02 16:42:26 INFO     valid size: 1848
2022-09-02 16:42:26 INFO     test size: 1846
2022-09-02 16:42:59 INFO     [Current Train Set] Size: 554 Pos: 64 Neg: 490 Per: 0.10 Acc: 1.0000
2022-09-02 16:42:59 INFO     [Teacher] epoch#1
2022-09-02 16:43:15 INFO     loss: 0.4105052718094417
2022-09-02 16:43:51 INFO     [Valid] Precision: 0.0000, Recall: 0.0000, F1: 0.0000
