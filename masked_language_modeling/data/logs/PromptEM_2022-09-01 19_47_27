2022-09-01 19:47:27 INFO     ====PromptEM Args====
2022-09-01 19:47:27 INFO     seed: 2022
2022-09-01 19:47:27 INFO     device: cuda
2022-09-01 19:47:27 INFO     model_name_or_path: roberta-base
2022-09-01 19:47:27 INFO     model_type: roberta
2022-09-01 19:47:27 INFO     batch_size: 64
2022-09-01 19:47:27 INFO     text_summarize: True
2022-09-01 19:47:27 INFO     learning_rate: 0.0001
2022-09-01 19:47:27 INFO     max_length: 512
2022-09-01 19:47:27 INFO     add_token: True
2022-09-01 19:47:27 INFO     data_name: semi-heter
2022-09-01 19:47:27 INFO     template_no: 0
2022-09-01 19:47:27 INFO     self_training: True
2022-09-01 19:47:27 INFO     dynamic_dataset: 8
2022-09-01 19:47:27 INFO     k: 0.1
2022-09-01 19:47:27 INFO     num_iter: 1
2022-09-01 19:47:27 INFO     pseudo_label_method: uncertainty
2022-09-01 19:47:27 INFO     confidence_ratio: 0.1
2022-09-01 19:47:27 INFO     mc_dropout_pass: 10
2022-09-01 19:47:27 INFO     uncertainty_ratio: 0.05
2022-09-01 19:47:27 INFO     el2n_ratio: 0.05
2022-09-01 19:47:27 INFO     save_model: False
2022-09-01 19:47:27 INFO     only_plm: True
2022-09-01 19:47:27 INFO     teacher_epochs: 20
2022-09-01 19:47:27 INFO     student_epochs: 30
2022-09-01 19:47:27 INFO     test_pseudo_label: 
2022-09-01 19:47:27 INFO     one_word: False
2022-09-01 19:48:04 INFO     num_sample_pos: 47
2022-09-01 19:48:04 INFO     num_sample_neg: 77
2022-09-01 19:48:04 INFO     left size: 22133, right size: 23264
2022-09-01 19:48:04 INFO     labeled train size: 124
2022-09-01 19:48:04 INFO     unlabeled train size: 1116
2022-09-01 19:48:04 INFO     valid size: 414
2022-09-01 19:48:04 INFO     test size: 414
2022-09-01 19:48:33 INFO     [Current Train Set] Size: 124 Pos: 47 Neg: 77 Per: 0.10 Acc: 1.0000
2022-09-01 19:48:33 INFO     [Teacher] epoch#1
2022-09-01 19:48:35 INFO     loss: 0.6877354979515076
2022-09-01 19:48:36 INFO     [Valid] Precision: 0.0952, Recall: 0.0127, F1: 0.0225
2022-09-01 19:48:37 INFO     [Test] Precision: 1.0000, Recall: 0.0440, F1: 0.0843
2022-09-01 19:48:37 INFO     [Teacher] epoch#2
2022-09-01 19:48:39 INFO     loss: 0.6841972470283508
2022-09-01 19:48:40 INFO     [Valid] Precision: 0.1429, Recall: 0.0064, F1: 0.0122
2022-09-01 19:48:41 INFO     [Test] Precision: 1.0000, Recall: 0.0252, F1: 0.0491
2022-09-01 19:48:41 INFO     [Teacher] epoch#3
2022-09-01 19:48:42 INFO     loss: 0.681854248046875
2022-09-01 19:48:44 INFO     [Valid] Precision: 0.2000, Recall: 0.0064, F1: 0.0123
2022-09-01 19:48:45 INFO     [Test] Precision: 1.0000, Recall: 0.0189, F1: 0.0370
2022-09-01 19:48:45 INFO     [Teacher] epoch#4
2022-09-01 19:48:46 INFO     loss: 0.6789861023426056
2022-09-01 19:48:48 INFO     [Valid] Precision: 0.3333, Recall: 0.0064, F1: 0.0125
2022-09-01 19:48:49 INFO     [Test] Precision: 1.0000, Recall: 0.0126, F1: 0.0248
2022-09-01 19:48:49 INFO     [Teacher] epoch#5
2022-09-01 19:48:50 INFO     loss: 0.6815320253372192
2022-09-01 19:48:51 INFO     [Valid] Precision: 0.3333, Recall: 0.0064, F1: 0.0125
2022-09-01 19:48:53 INFO     [Test] Precision: 1.0000, Recall: 0.0126, F1: 0.0248
2022-09-01 19:48:53 INFO     [Teacher] epoch#6
2022-09-01 19:48:54 INFO     loss: 0.6763229370117188
2022-09-01 19:48:55 INFO     [Valid] Precision: 1.0000, Recall: 0.0064, F1: 0.0127
2022-09-01 19:48:56 INFO     [Test] Precision: 0.0000, Recall: 0.0000, F1: 0.0000
2022-09-01 19:48:56 INFO     [Teacher] epoch#7
2022-09-01 19:48:58 INFO     loss: 0.6808723509311676
2022-09-01 19:48:59 INFO     [Valid] Precision: 1.0000, Recall: 0.0064, F1: 0.0127
2022-09-01 19:49:00 INFO     [Test] Precision: 0.0000, Recall: 0.0000, F1: 0.0000
2022-09-01 19:49:00 INFO     [Teacher] epoch#8
2022-09-01 19:49:01 INFO     loss: 0.6715860962867737
2022-09-01 19:49:03 INFO     [Valid] Precision: 0.0000, Recall: 0.0000, F1: 0.0000
2022-09-01 19:49:04 INFO     [Test] Precision: 0.0000, Recall: 0.0000, F1: 0.0000
2022-09-01 19:49:04 INFO     [Teacher] epoch#9
2022-09-01 19:49:05 INFO     loss: 0.674496203660965
2022-09-01 19:49:07 INFO     [Valid] Precision: 0.0000, Recall: 0.0000, F1: 0.0000
