2022-09-11 17:13:09 INFO     ====AdapterEM Args====
2022-09-11 17:13:09 INFO     seed: 2022
2022-09-11 17:13:09 INFO     device: cuda
2022-09-11 17:13:09 INFO     model_name_or_path: bert-vanilla
2022-09-11 17:13:09 INFO     model_type: bert
2022-09-11 17:13:09 INFO     batch_size: 16
2022-09-11 17:13:09 INFO     text_summarize: True
2022-09-11 17:13:09 INFO     learning_rate: 0.0002
2022-09-11 17:13:09 INFO     max_length: 512
2022-09-11 17:13:09 INFO     add_token: True
2022-09-11 17:13:09 INFO     data_name: rel-text
2022-09-11 17:13:09 INFO     template_no: 0
2022-09-11 17:13:09 INFO     self_training: False
2022-09-11 17:13:09 INFO     dynamic_dataset: -1
2022-09-11 17:13:09 INFO     k: 0.1
2022-09-11 17:13:09 INFO     num_iter: 1
2022-09-11 17:13:09 INFO     pseudo_label_method: uncertainty
2022-09-11 17:13:09 INFO     confidence_ratio: 0.1
2022-09-11 17:13:09 INFO     mc_dropout_pass: 10
2022-09-11 17:13:09 INFO     uncertainty_ratio: 0.05
2022-09-11 17:13:09 INFO     el2n_ratio: 0.05
2022-09-11 17:13:09 INFO     save_model: False
2022-09-11 17:13:09 INFO     only_plm: True
2022-09-11 17:13:09 INFO     teacher_epochs: 60
2022-09-11 17:13:09 INFO     student_epochs: 30
2022-09-11 17:13:09 INFO     test_pseudo_label: 
2022-09-11 17:13:09 INFO     adapter_size: 4
2022-09-11 17:13:09 INFO     one_word: False
2022-09-11 17:13:26 INFO     num_sample_pos: 133
2022-09-11 17:13:26 INFO     num_sample_neg: 608
2022-09-11 17:13:26 INFO     left size: 2616, right size: 2294
2022-09-11 17:13:26 INFO     labeled train size: 741
2022-09-11 17:13:26 INFO     unlabeled train size: 6676
2022-09-11 17:13:26 INFO     valid size: 2473
2022-09-11 17:13:26 INFO     test size: 2473
2022-09-11 17:13:56 INFO     [Current Train Set] Size: 741 Pos: 133 Neg: 608 Per: 0.10 Acc: 1.0000
2022-09-11 17:13:56 INFO     [Teacher] epoch#1
2022-09-11 17:14:14 INFO     loss: 0.476174163691541
2022-09-11 17:14:57 INFO     [Valid] Precision: 0.0000, Recall: 0.0000, F1: 0.0000
2022-09-11 17:15:42 INFO     [Test] Precision: 0.0000, Recall: 0.0000, F1: 0.0000
2022-09-11 17:15:42 INFO     [Teacher] epoch#2
2022-09-11 17:16:07 INFO     loss: 0.47250713598220906
2022-09-11 17:16:51 INFO     [Valid] Precision: 0.0000, Recall: 0.0000, F1: 0.0000
2022-09-11 17:17:34 INFO     [Test] Precision: 0.0000, Recall: 0.0000, F1: 0.0000
2022-09-11 17:17:34 INFO     [Teacher] epoch#3
2022-09-11 17:18:05 INFO     loss: 0.4919503153638637
2022-09-11 17:18:48 INFO     [Valid] Precision: 0.0000, Recall: 0.0000, F1: 0.0000
2022-09-11 17:19:33 INFO     [Test] Precision: 0.0000, Recall: 0.0000, F1: 0.0000
2022-09-11 17:19:33 INFO     [Teacher] epoch#4
2022-09-11 17:20:05 INFO     loss: 0.4996186520190949
2022-09-11 17:20:48 INFO     [Valid] Precision: 0.0000, Recall: 0.0000, F1: 0.0000
2022-09-11 17:21:31 INFO     [Test] Precision: 0.0000, Recall: 0.0000, F1: 0.0000
2022-09-11 17:21:31 INFO     [Teacher] epoch#5
2022-09-11 17:22:02 INFO     loss: 0.48444843672691507
2022-09-11 17:22:47 INFO     [Valid] Precision: 0.0000, Recall: 0.0000, F1: 0.0000
2022-09-11 17:23:31 INFO     [Test] Precision: 0.0000, Recall: 0.0000, F1: 0.0000
2022-09-11 17:23:31 INFO     [Teacher] epoch#6
2022-09-11 17:24:02 INFO     loss: 0.4706028554033726
2022-09-11 17:24:46 INFO     [Valid] Precision: 0.0000, Recall: 0.0000, F1: 0.0000
2022-09-11 17:25:29 INFO     [Test] Precision: 0.0000, Recall: 0.0000, F1: 0.0000
2022-09-11 17:25:29 INFO     [Teacher] epoch#7
2022-09-11 17:26:00 INFO     loss: 0.46873097533875324
2022-09-11 17:26:45 INFO     [Valid] Precision: 0.0000, Recall: 0.0000, F1: 0.0000
2022-09-11 17:27:28 INFO     [Test] Precision: 0.0000, Recall: 0.0000, F1: 0.0000
2022-09-11 17:27:28 INFO     [Teacher] epoch#8
2022-09-11 17:28:00 INFO     loss: 0.488456759047001
2022-09-11 17:28:44 INFO     [Valid] Precision: 0.0000, Recall: 0.0000, F1: 0.0000
2022-09-11 17:29:26 INFO     [Test] Precision: 0.0000, Recall: 0.0000, F1: 0.0000
2022-09-11 17:29:26 INFO     [Teacher] epoch#9
2022-09-11 17:29:58 INFO     loss: 0.4745802210366472
2022-09-11 17:30:43 INFO     [Valid] Precision: 0.0000, Recall: 0.0000, F1: 0.0000
