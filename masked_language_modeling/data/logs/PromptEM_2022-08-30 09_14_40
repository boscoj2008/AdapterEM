2022-08-30 09:14:40 INFO     ====PromptEM Args====
2022-08-30 09:14:40 INFO     seed: 2022
2022-08-30 09:14:40 INFO     device: cuda
2022-08-30 09:14:40 INFO     model_name_or_path: roberta-base
2022-08-30 09:14:40 INFO     model_type: roberta
2022-08-30 09:14:40 INFO     batch_size: 32
2022-08-30 09:14:40 INFO     text_summarize: True
2022-08-30 09:14:40 INFO     learning_rate: 2e-05
2022-08-30 09:14:40 INFO     max_length: 512
2022-08-30 09:14:40 INFO     add_token: True
2022-08-30 09:14:40 INFO     data_name: rel-heter
2022-08-30 09:14:40 INFO     template_no: 0
2022-08-30 09:14:40 INFO     self_training: True
2022-08-30 09:14:40 INFO     dynamic_dataset: -1
2022-08-30 09:14:40 INFO     k: 0.1
2022-08-30 09:14:40 INFO     num_iter: 1
2022-08-30 09:14:40 INFO     pseudo_label_method: uncertainty
2022-08-30 09:14:40 INFO     confidence_ratio: 0.1
2022-08-30 09:14:40 INFO     mc_dropout_pass: 10
2022-08-30 09:14:40 INFO     uncertainty_ratio: 0.05
2022-08-30 09:14:40 INFO     el2n_ratio: 0.05
2022-08-30 09:14:40 INFO     save_model: False
2022-08-30 09:14:40 INFO     only_plm: True
2022-08-30 09:14:40 INFO     teacher_epochs: 100
2022-08-30 09:14:40 INFO     student_epochs: 100
2022-08-30 09:14:40 INFO     test_pseudo_label: 
2022-08-30 09:14:40 INFO     one_word: False
2022-08-30 09:14:55 INFO     num_sample_pos: 7
2022-08-30 09:14:55 INFO     num_sample_neg: 50
2022-08-30 09:14:55 INFO     left size: 533, right size: 331
2022-08-30 09:14:55 INFO     labeled train size: 57
2022-08-30 09:14:55 INFO     unlabeled train size: 510
2022-08-30 09:14:55 INFO     valid size: 190
2022-08-30 09:14:55 INFO     test size: 189
2022-08-30 09:15:24 INFO     [Current Train Set] Size: 57 Pos: 7 Neg: 50 Per: 0.10 Acc: 1.0000
2022-08-30 09:15:24 INFO     [Teacher] epoch#1
2022-08-30 09:15:25 INFO     loss: 1.1884665489196777
2022-08-30 09:15:25 INFO     [Valid] Precision: 0.1158, Recall: 1.0000, F1: 0.2075
2022-08-30 09:15:25 INFO     [Test] Precision: 0.1164, Recall: 1.0000, F1: 0.2085
2022-08-30 09:15:25 INFO     [Teacher] epoch#2
2022-08-30 09:15:25 INFO     loss: 1.1646259427070618
2022-08-30 09:15:25 INFO     [Valid] Precision: 0.1158, Recall: 1.0000, F1: 0.2075
2022-08-30 09:15:26 INFO     [Test] Precision: 0.1164, Recall: 1.0000, F1: 0.2085
2022-08-30 09:15:26 INFO     [Teacher] epoch#3
2022-08-30 09:15:26 INFO     loss: 1.035374253988266
2022-08-30 09:15:26 INFO     [Valid] Precision: 0.1158, Recall: 1.0000, F1: 0.2075
2022-08-30 09:15:26 INFO     [Test] Precision: 0.1164, Recall: 1.0000, F1: 0.2085
2022-08-30 09:15:26 INFO     [Teacher] epoch#4
2022-08-30 09:15:27 INFO     loss: 1.0459542274475098
2022-08-30 09:15:27 INFO     [Valid] Precision: 0.1158, Recall: 1.0000, F1: 0.2075
2022-08-30 09:15:27 INFO     [Test] Precision: 0.1164, Recall: 1.0000, F1: 0.2085
2022-08-30 09:15:27 INFO     [Teacher] epoch#5
2022-08-30 09:15:27 INFO     loss: 0.9302403032779694
2022-08-30 09:15:28 INFO     [Valid] Precision: 0.1158, Recall: 1.0000, F1: 0.2075
2022-08-30 09:15:28 INFO     [Test] Precision: 0.1164, Recall: 1.0000, F1: 0.2085
2022-08-30 09:15:28 INFO     [Teacher] epoch#6
2022-08-30 09:15:28 INFO     loss: 0.8663404881954193
2022-08-30 09:15:28 INFO     [Valid] Precision: 0.1176, Recall: 1.0000, F1: 0.2105
2022-08-30 09:15:29 INFO     [Test] Precision: 0.1183, Recall: 1.0000, F1: 0.2115
2022-08-30 09:15:29 INFO     [Teacher] epoch#7
2022-08-30 09:15:29 INFO     loss: 0.8067063987255096
2022-08-30 09:15:29 INFO     [Valid] Precision: 0.1105, Recall: 0.9091, F1: 0.1970
2022-08-30 09:15:29 INFO     [Test] Precision: 0.1141, Recall: 0.9545, F1: 0.2039
2022-08-30 09:15:29 INFO     [Teacher] epoch#8
2022-08-30 09:15:29 INFO     loss: 0.8315243721008301
2022-08-30 09:15:30 INFO     [Valid] Precision: 0.1092, Recall: 0.8636, F1: 0.1939
2022-08-30 09:15:30 INFO     [Test] Precision: 0.0970, Recall: 0.7273, F1: 0.1711
2022-08-30 09:15:30 INFO     [Teacher] epoch#9
2022-08-30 09:15:30 INFO     loss: 0.7651186585426331
2022-08-30 09:15:30 INFO     [Valid] Precision: 0.0940, Recall: 0.6364, F1: 0.1637
2022-08-30 09:15:31 INFO     [Test] Precision: 0.0890, Recall: 0.5909, F1: 0.1548
2022-08-30 09:15:31 INFO     [Teacher] epoch#10
2022-08-30 09:15:31 INFO     loss: 0.7860049605369568
2022-08-30 09:15:31 INFO     [Valid] Precision: 0.1091, Recall: 0.5455, F1: 0.1818
2022-08-30 09:15:31 INFO     [Test] Precision: 0.1058, Recall: 0.5000, F1: 0.1746
2022-08-30 09:15:31 INFO     [Teacher] epoch#11
2022-08-30 09:15:32 INFO     loss: 0.6899756789207458
2022-08-30 09:15:32 INFO     [Valid] Precision: 0.1316, Recall: 0.4545, F1: 0.2041
2022-08-30 09:15:32 INFO     [Test] Precision: 0.1077, Recall: 0.3182, F1: 0.1609
2022-08-30 09:15:32 INFO     [Teacher] epoch#12
2022-08-30 09:15:32 INFO     loss: 0.6473572254180908
2022-08-30 09:15:33 INFO     [Valid] Precision: 0.1795, Recall: 0.3182, F1: 0.2295
2022-08-30 09:15:33 INFO     [Test] Precision: 0.1176, Recall: 0.1818, F1: 0.1429
2022-08-30 09:15:33 INFO     [Teacher] epoch#13
2022-08-30 09:15:33 INFO     loss: 0.6297397315502167
2022-08-30 09:15:33 INFO     [Valid] Precision: 0.2941, Recall: 0.2273, F1: 0.2564
2022-08-30 09:15:33 INFO     [Test] Precision: 0.0588, Recall: 0.0455, F1: 0.0513
2022-08-30 09:15:33 INFO     [Teacher] epoch#14
2022-08-30 09:15:34 INFO     loss: 0.5172746479511261
2022-08-30 09:15:34 INFO     [Valid] Precision: 0.4000, Recall: 0.0909, F1: 0.1481
2022-08-30 09:15:34 INFO     [Test] Precision: 0.1667, Recall: 0.0455, F1: 0.0714
2022-08-30 09:15:34 INFO     [Teacher] epoch#15
2022-08-30 09:15:34 INFO     loss: 0.5614396035671234
2022-08-30 09:15:35 INFO     [Valid] Precision: 0.0000, Recall: 0.0000, F1: 0.0000
2022-08-30 09:15:35 INFO     [Test] Precision: 0.0000, Recall: 0.0000, F1: 0.0000
2022-08-30 09:15:35 INFO     [Teacher] epoch#16
2022-08-30 09:15:35 INFO     loss: 0.505128338932991
